{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT 5196 Assignment 2\n",
    "* Name: Peiyu Liu\n",
    "* Student number: 31153291\n",
    "* Date: 20/05/2021\n",
    "\n",
    "## Libraries used:\n",
    "* pandas(Process data, read and input csv files, convert and filter data.)\n",
    "* re(Regular expression function, used for regular expression matching and replacement, to find matching objects.)\n",
    "* linalg(The numpy.linalg module contains functions for linear algebra. Using this module, calculate the inverse matrix, find eigenvalues, solve linear equations, and solve determinants.)\n",
    "* numpy(N-dimensional array object ndarray, dimensional array and matrix operations.)\n",
    "* LinearRegression(A statistical analysis method to determine the quantitative relationship between two or more variables)\n",
    "* matplotlib(Graphicalize the data and provide a variety of output formats.)\n",
    "* math(Mathematical functions for floating-point numbers)\n",
    "\n",
    "## 1. Introduction\n",
    "* For assignment 2, there are three sample data files that all contain many issue data. For dirty file, all data should be corrected into correct formulas. For missing file, all rows which are lack accurate data should be removed. For the outlier file, all outlier data should be deleted. Finally, code can output three files that contain data accurate formula. Use pandas to read the CSV database and analyse files' procedure and data. Compare data with the correct formula, then use python functions to modify data. Use lambda to travelsal data and use condition to find expected data. Change data to accurate formular or detele issue data. Check each row and each column to ensure their data is accurate. Data can be performed as graphical and non-graphical to check their correctness. \n",
    "\n",
    "**details in code sections**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assignment coding\n",
    "### import libraries\n",
    "- pandas, re, numpy, LinearRegression, matplotlib, math (see in Libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input dirty data file and use desribe(), count() functions to check data format and file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file = pd.read_csv('31153291/31153291_dirty_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.describe() # observe data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.count() # observe data numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check order id\n",
    "* order id should be unique, set() can check repeated id.\n",
    "* If id numbers is equal to unique id numbers, it means each id is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirty_file.sales_id) == len(set(dirty_file.sales_id)) # result is true-no repeated id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check date\n",
    "* date fomart should be DD/MM/YYYY.\n",
    "* use apply and lambda to traversal data.\n",
    "* use regression '\\W' to split each date into three parts.\n",
    "* Use lambda to traversal each date and check date length is more than 3- day,month,year\n",
    "* x[0] means day, x[1] means month, x[-1] means year\n",
    "* month value should be less than 12, year's length should be more than 2, day's length should be less than 3.\n",
    "\n",
    "##### Reference: \n",
    "* apply() and lambda() https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "* pd.at() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date\n",
    "dirty_file.date = dirty_file.date.apply(lambda x: re.split('\\W', x)) # split data into 3 parts.\n",
    "update_container = []  \n",
    "update_container += dirty_file.date[dirty_file.date.apply(lambda x: len(x) > 3)].index.to_list() \n",
    "dirty_file.date = dirty_file.date.apply(lambda x: [flag for flag in x[1:] if flag] if len(x) > 3 else [flag for flag in x]) # traversal each month data.\n",
    "dirty_file.date[dirty_file.date.apply(lambda x: x[1] > '12')] # month data value should no more than 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(update_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.date[dirty_file.date.apply(lambda x: x[1] > '12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.date[dirty_file.date.apply(lambda x: len(x[0]) > 2)] # day's length should no more than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use iterrows to traversal each row. after compare each day,month and year, change their orders.\n",
    "# x[0] means day, x[1] means month, x[-1] means year\n",
    "# month value should be less than 12, year's length should be more than 2, day's length should be less than 3.\n",
    "# Reference: pd.at() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n",
    "\n",
    "for each_index,row in dirty_file.iterrows():\n",
    "    date_extract = row.date\n",
    "    if len(date_extract[0]) > 2:\n",
    "        dirty_file.at[each_index, 'date'] = [date_extract[-1], date_extract[1], date_extract[0]]\n",
    "        update_container.append(each_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change each date into DD/MM/YYYY format.\n",
    "dirty_file.date = dirty_file.date.apply(lambda x: '/'.join([flag for flag in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check time\n",
    "* Use lambda to traversal each row and split each time by ':'.\n",
    "* time will be divided into 3 parts.\n",
    "* accurate time format is hh:mm:ss.\n",
    "* hh no more than 24, mm and ss no more than 60.\n",
    "\n",
    "##### Reference: \n",
    "* apply() and lambda() https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "* index.isin() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.isin.html?highlight=isin#pandas.Index.isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.time = dirty_file.time.apply(lambda x: [flag for flag in x.split(':')]) # traversal time and split time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.time[dirty_file.time.apply(lambda x: x[0] >='24')] # x[0] is hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.time[dirty_file.time.apply(lambda x: x[1] >= '60' or x[2] >= '60')] # x[1] and x[2] are minutes and seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_container += dirty_file.time[dirty_file.time.apply(lambda x: x[0] >= '24')].index.to_list() # extract issue time, hour > 24\n",
    "dirty_file.time = dirty_file.time.apply(lambda x: [x[1], x[0], x[2]] if x[0] >= '24' else x) # traversal issue time and change 3 parts orders.\n",
    "dirty_file.time[dirty_file.time.apply(lambda x: x[0] >= '24')]\n",
    "dirty_file[dirty_file.index.isin(update_container)] # use isin to check is there still has issue time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.time = dirty_file.time.apply(lambda x: \":\".join([flag for flag in x])) # re-format time into hh:mm:ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check parcel_size\n",
    "* parcel_size can only have three values: small,medium,large\n",
    "* use unique to check values\n",
    "* use lambda to traversal each data and find out issue data.\n",
    "* use lambda to traversal and modify values into accurate formats.\n",
    "\n",
    "##### Reference: \n",
    "* apply() and lambda() https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "* unique() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html?highlight=unique#pandas.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.parcel_size.unique() # check unique values\n",
    "update_container += dirty_file.parcel_size[dirty_file.parcel_size.apply(lambda x: x in ['L','S','M'])].index.to_list() # traversal and find out issue data.\n",
    "dirty_file.parcel_size = dirty_file.parcel_size.apply(lambda x: 'large' if x == 'L' else x) # change value into accurate value.\n",
    "dirty_file.parcel_size = dirty_file.parcel_size.apply(lambda x: 'medium' if x == 'M' else x)\n",
    "dirty_file.parcel_size = dirty_file.parcel_size.apply(lambda x: 'small' if x == 'S' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.parcel_size.unique() # check results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check latitude and longtitude\n",
    "* use plot() to generate diagram to analyse geographical data.\n",
    "* use abs() to compare absolute values of latitude and longitude.\n",
    "* use loc to extract latitude and longitude data.\n",
    "* change geographical data into accurate format.\n",
    "\n",
    "##### Reference:\n",
    "* plot(): https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html?highlight=plot#pandas.DataFrame.plot\n",
    "* pd.loc[]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html?highlight=loc#pandas.DataFrame.loc\n",
    "* plot latitude and longitude: https://jakevdp.github.io/PythonDataScienceHandbook/04.13-geographic-data-with-basemap.html  & https://stackoverflow.com/questions/53233228/plot-latitude-longitude-from-csv-in-python-3-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.plot(kind = 'scatter', x = 'Customer_lat', y = 'Customer_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot latitude and longitude: https://jakevdp.github.io/PythonDataScienceHandbook/04.13-geographic-data-with-basemap.html  & https://stackoverflow.com/questions/53233228/plot-latitude-longitude-from-csv-in-python-3-6\n",
    "\n",
    "for each_index, row in dirty_file.iterrows():\n",
    "    latitude_data,longitude_data = row.Customer_lat, row.Customer_long\n",
    "    if abs(latitude_data) > abs(longitude_data):\n",
    "        dirty_file.loc[each_index, 'Customer_lat'] = -1*abs(longitude_data)\n",
    "        dirty_file.loc[each_index, 'Customer_long'] = abs(latitude_data)\n",
    "        update_container.append(each_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.plot(kind = 'scatter', x = 'Customer_lat', y = 'Customer_long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check loyalty\n",
    "* only have value 0 or 1\n",
    "* use unique to check value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.isLoyaltyProgram.unique() # results are 1 and 0. no issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check storehouse\n",
    "* storehouse has unique id: 2,4,3,0,6.\n",
    "* use dictionary and zip() to group storehouse name and geographical data.\n",
    "* use unique to check values.\n",
    "* 2 is Footscray.\n",
    "* 0 is Clayton.\n",
    "* 4 is Sunshine.\n",
    "* 3 is St. Kilda.\n",
    "\n",
    "##### Reference: \n",
    "* to_numpy():https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html?highlight=to_numpy#pandas.DataFrame.to_numpy &  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.to_numpy.html?highlight=to_numpy#pandas.Index.to_numpy\n",
    "* loc:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html?highlight=loc#pandas.DataFrame.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_data = pd.read_csv('Storehouses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_data.describe() # analyse storehouse structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_house: {Name: lat, lon}\n",
    "stores_dict = dict(zip(stores_data.names.to_numpy(), stores_data[['lat','lon']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.nearest_storehouse_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.nearest_storehouse == 'Eping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id: 2,4,3,0 only has one value\n",
    "#  2 is Footscray.\n",
    "# 0 is Clayton.\n",
    "# 4 is Sunshine.\n",
    "# 3 is St. Kilda\n",
    "dirty_file[dirty_file.nearest_storehouse_id == 2].nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.nearest_storehouse_id == 0].nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.nearest_storehouse_id == 4].nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.nearest_storehouse_id == 3].nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 has multiple values.\n",
    "dirty_file[dirty_file.nearest_storehouse_id == 6].nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_data.names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.nearest_storehouse_id == 6]['nearest_storehouse'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Clayton', 'Eping', 'Footscray', 'St. Kilda', 'Sunshine']\n",
    "house_names = stores_data.names.tolist()\n",
    "for each_index, row in dirty_file.iterrows():\n",
    "    if row.nearest_storehouse_id == 6:\n",
    "        dirty_file.loc[each_index, 'nearest_storehouse_id'] == house_names.index(row.nearest_storehouse)\n",
    "        update_container.append(each_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check dist_to_nearest_storehouse\n",
    "* The distance between two points is calculated, the position of the point on the earth is in the form of latitude and longitude coordinates.\n",
    "* earth is 6371\n",
    "* use radians to calculate difference between range of latitude, Manually convert numbers to radians.\n",
    "* use sin and cos to calculate difference.\n",
    "\n",
    "#### Reference: \n",
    "* Getting distance between two points based on latitude/longitude: https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "* Geographiclib: https://geographiclib.sourceforge.io/html/python/code.html#module-geographiclib.geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "def dist_difference(lat1, lon1, lat2, lon2):\n",
    "    r = 6371\n",
    "    dlat = math.radians(lat2 - lat1) # Manually convert numbers to radians\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) \\\n",
    "        * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = r * c\n",
    "    return round(d, 2)\n",
    "\n",
    "# compare data and calculated results, if equal, then correct.\n",
    "for each_index, row in dirty_file.iterrows():\n",
    "    if each_index in update_container:\n",
    "        continue\n",
    "    name_store = row.nearest_storehouse\n",
    "    dist_store = row.dist_to_nearest_storehouse\n",
    "    lat1, lon1 = row.Customer_lat, row.Customer_long\n",
    "    lat2, lon2 = stores_dict[name_store]\n",
    "    dist = dist_difference(lat1, lon1, lat2, lon2)\n",
    "    if dist != dist_store: \n",
    "        dirty_file.loc[each_index, 'dist_to_nearest_storehouse'] = dist\n",
    "        update_container.append(each_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check price and shopping_cart\n",
    "* analyse shopping_cart data structure.\n",
    "* find all products and calculate products' numbers.\n",
    "* use dictionary to zip products' names and numbers.\n",
    "* change dictionary to dataframe format.\n",
    "\n",
    "#### Reference:\n",
    "* array: https://numpy.org/doc/stable/reference/generated/numpy.array.html?highlight=array#numpy.array\n",
    "* matrix: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html?highlight=matrix#numpy.matrix\n",
    "* linalg.solve():https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html#numpy.linalg.solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_sample = dirty_file.shopping_cart.values[0]\n",
    "cart_sample\n",
    "product_data = dirty_file.shopping_cart.apply(lambda x: re.findall(r'\\w+', x)).sum()\n",
    "product_data = list(set([flag for flag in product_data if len(flag) > 2]))\n",
    "product_dict = dict(zip(product_data, [[0 for _ in range(len(product_data))] for _ in range(len(product_data))]))\n",
    "product_number = pd.DataFrame(product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each item price\n",
    "product_container = []\n",
    "price_cal = 0\n",
    "for each_index, row in dirty_file.iterrows():\n",
    "    pro_list = re.findall(r'\\w+',row.shopping_cart)\n",
    "    for i in range(0,len(pro_list),2):\n",
    "        product_number.loc[each_index,pro_list[i]] = int(pro_list[i+1])\n",
    "    product_container.append(row.price)\n",
    "    if each_index >= 7:\n",
    "        break\n",
    "        # Solve linear matrices in matrix form\n",
    "        # https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html\n",
    "price_list = np.linalg.solve(np.matrix(product_number), np.array(product_container))\n",
    "price_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dictionary to group products and single price\n",
    "dict_each_price = dict(zip(product_data,[round(flag,4) for flag in price_list]))\n",
    "dict_each_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use product numbers and single price to calculate amount.\n",
    "def price_compare(shopping_cart,dict_each_price = dict_each_price):\n",
    "    price = 0\n",
    "    pro_list = re.findall(r'\\w+',shopping_cart)\n",
    "    for i in range(0,len(pro_list),2):\n",
    "        price += dict_each_price[pro_list[i]]*int(pro_list[i+1]) # prince = single_price*numbers\n",
    "    return round(price,2) # price format xx.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results and price, same is accurate price.\n",
    "price_compare(row.shopping_cart), row.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file[dirty_file.shopping_cart.apply(lambda x: price_compare(x)) == dirty_file.price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(update_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delivery cost\n",
    "* no anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "### In missing file, some rows have empty data, input this row.\n",
    "* use isna() to detect missing value.\n",
    "* month 12,1,2 is one season.\n",
    "* month 3,4,5 is one season.\n",
    "* month 6,7,8 is one season.\n",
    "* month 9,10,11 is one season.\n",
    "* generate model (x,y) contain distance, season and cost.\n",
    "* use linear regression to fit this model.\n",
    "* Return the coefficient of determination  of the prediction.\n",
    "* Predict using the linear model.\n",
    "\n",
    "##### Reference: \n",
    "* isna() :https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html\n",
    "* dropna(): drop missing data https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "* linearRegression:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* fit(): Fit linear model.https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* reshape():Gives a new shape to an array without changing its data.https://numpy.org/doc/stable/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read file\n",
    "* pd.read_csv()\n",
    "* observe data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file = pd.read_csv('31153291/31153291_missing_data.csv')\n",
    "missing_file.head()\n",
    "missing_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file[missing_file.shopping_cart.apply(lambda x: price_compare(x)) != missing_file.price]\n",
    "missing_file.price = missing_file.shopping_cart.apply(lambda x: price_compare(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check storehouse values.\n",
    "missing_file.nearest_storehouse.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect missing values.\n",
    "# Reference: isna():https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html\n",
    "missing_file[missing_file.delivery_cost.isna()].nearest_storehouse.unique()\n",
    "missing_file[(missing_file.delivery_cost.isna()) & (missing_file.nearest_storehouse == 'Sunshine')].date.apply(lambda x: x.split('/')[1]).unique()\n",
    "missing_file[(missing_file.delivery_cost.isna()) & (missing_file.nearest_storehouse == 'Footscray')].date.apply(lambda x: x.split('/')[1]).unique()\n",
    "missing_file[(missing_file.delivery_cost.isna()) & (missing_file.nearest_storehouse == 'St. Kilda')].date.apply(lambda x: x.split('/')[1]).unique()\n",
    "missing_file[(missing_file.delivery_cost.isna()) & (missing_file.nearest_storehouse == 'Clayton')].date.apply(lambda x: x.split('/')[1]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_file[missing_file.nearest_storehouse == 'Clayton'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file['season'] = np.nan # Special values defined in numpy: nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month 12,1,2 is one season.\n",
    "# month 3,4,5 is one season.\n",
    "# month 6,7,8 is one season.\n",
    "# month 9,10,11 is one season.\n",
    "# x[1] is month index.\n",
    "missing_file.loc[missing_file.date.apply(lambda x: x.split('/')[1] in ['12', '01', '02']), 'season'] = 1\n",
    "missing_file.loc[missing_file.date.apply(lambda x: x.split('/')[1] in ['03', '04', '05']), 'season'] = 2\n",
    "missing_file.loc[missing_file.date.apply(lambda x: x.split('/')[1] in ['06', '07', '08']), 'season'] = 3\n",
    "missing_file.loc[missing_file.date.apply(lambda x: x.split('/')[1] in ['09', '10', '11']), 'season'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing data\n",
    "missing_drop = missing_file.dropna()\n",
    "sun_data = missing_drop[missing_drop.nearest_storehouse == 'Sunshine']\n",
    "foot_data = missing_drop[missing_drop.nearest_storehouse == 'Footscray']\n",
    "stkilda_data = missing_drop[missing_drop.nearest_storehouse == 'St. Kilda']\n",
    "clayton_data = missing_drop[missing_drop.nearest_storehouse == 'Clayton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# generate model (x,y) contain distance, season and cost.\n",
    "# use linear regression to fit this model.\n",
    "# Return the coefficient of determination  of the prediction.\n",
    "# Predict using the linear model.\n",
    "# Sunshine\n",
    "x = sun_data[['dist_to_nearest_storehouse', 'season']]\n",
    "y = sun_data.delivery_cost\n",
    "reg_sunshine = LinearRegression().fit(x,y) # fit modle x,y\n",
    "reg_sunshine.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# generate model (x,y) contain distance, season and cost.\n",
    "# use linear regression to fit this model.\n",
    "# Return the coefficient of determination  of the prediction.\n",
    "# Predict using the linear model.\n",
    "# Footscray\n",
    "x = foot_data[['dist_to_nearest_storehouse', 'season']]\n",
    "y = foot_data.delivery_cost\n",
    "reg_foot = LinearRegression().fit(x,y)\n",
    "reg_foot.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# generate model (x,y) contain distance, season and cost.\n",
    "# use linear regression to fit this model.\n",
    "# Return the coefficient of determination  of the prediction.\n",
    "# Predict using the linear model.\n",
    "# St. Kilda\n",
    "x = stkilda_data[['dist_to_nearest_storehouse', 'season']]\n",
    "y = stkilda_data.delivery_cost\n",
    "reg_stkilda = LinearRegression().fit(x,y)\n",
    "reg_stkilda.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# generate model (x,y) contain distance, season and cost.\n",
    "# use linear regression to fit this model.\n",
    "# Return the coefficient of determination  of the prediction.\n",
    "# Predict using the linear model.\n",
    "# Clayton\n",
    "x = clayton_data[['dist_to_nearest_storehouse', 'season']]\n",
    "y = clayton_data.delivery_cost\n",
    "reg_clayton = LinearRegression().fit(x,y)\n",
    "reg_clayton.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_container = missing_file[missing_file.delivery_cost.isna()].index.tolist() # detect missing value\n",
    "missing_container # result is empty, removed all missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# predict Predict using the linear model.\n",
    "for each_index, row in missing_file.iterrows():\n",
    "    if each_index not in missing_container:\n",
    "        continue\n",
    "    x = np.array(row[['dist_to_nearest_storehouse', 'season']]).reshape(1,-1)\n",
    "    if row.nearest_storehouse == 'Sunshine':\n",
    "        cost_delivery = reg_sunshine.predict(x)[0]\n",
    "    elif row.nearest_storehouse == 'Footscray':\n",
    "        cost_delivery = reg_foot.predict(x)[0]\n",
    "    elif row.nearest_storehouse == 'St. Kilda':\n",
    "        cost_delivery = reg_stkilda.predict(x)[0]\n",
    "    else:\n",
    "        cost_delivery = reg_clayton.predict(x)[0]\n",
    "    \n",
    "    missing_file.loc[each_index, 'delivery_cost'] = cost_delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(row[['dist_to_nearest_storehouse', 'season']]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "* remove all outlier data\n",
    "* use boxplot to draw boxplot digram to analyse data.\n",
    "\n",
    "##### Reference:\n",
    "* boxplot: https://seaborn.pydata.org/generated/seaborn.boxplot.html & https://jwalton.info/Matplotlib-custom-boxplots/\n",
    "* percentile: https://numpy.org/doc/stable/reference/generated/numpy.percentile.html?highlight=percentile#numpy.percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file = pd.read_csv('31153291/31153291_outlier_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.boxplot(column = 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate upper and lower bond in boxplot.\n",
    "# the most extreme data point within (75%-25%)data range.\n",
    "# https://stackoverflow.com/questions/17725927/boxplots-in-matplotlib-markers-and-outliers\n",
    "def outlier_bond(data):\n",
    "    part_1 = np.percentile(data,25)\n",
    "    part_2 = np.percentile(data,75)\n",
    "    Interquartile = part_2-part_1\n",
    "    bottom = part_1 - 1.5*Interquartile\n",
    "    top = part_2 + 1.5*Interquartile\n",
    "    return bottom, top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_price, top_price = outlier_bond(outlier_file.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price outliers\n",
    "# compare price and (max and min range)\n",
    "outlier_file = outlier_file[(outlier_file.price >= bottom_price) & (outlier_file.price <= top_price)]\n",
    "outlier_file.boxplot(column = 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.boxplot(column = 'dist_to_nearest_storehouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.boxplot(column = 'delivery_cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(outlier_file.delivery_cost)\n",
    "plt.xlabel('Delivery cost')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Delivery cost diagram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_delivery, top_delivery = outlier_bond(outlier_file.delivery_cost)\n",
    "bottom_delivery,top_delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file = outlier_file[(outlier_file.delivery_cost >= 0)& (outlier_file.delivery_cost <= top_delivery)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.boxplot(column = 'delivery_cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_file.to_csv('31153291_outlier_data_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file.to_csv('31153291_missing_data_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_file.to_csv('31153291_dirty_data_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary\n",
    "\n",
    "_When I do assignment 2, I observe data and its format in a dirty file, missing file and outlier file. Before I code these three tasks, I understand what issues in these sample files and what is the correct format. Then I search relevant questions and teaching material online. I set my coding logic, and then I start with coding. When I do this assignment, I faced many challenges, like I do not know how to calculate the difference between latitude and longitude, so I search solution online and use this solution by retrieve reference. Assignment 2 let me learn many data frames and NumPy packages. I learned many convenient methods to deal with raw data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reference\n",
    "\n",
    "* apply() and lambda() https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "* pd.at() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n",
    "* apply() and lambda() https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "* unique() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html?highlight=unique#pandas.unique\n",
    "* plot(): https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html?highlight=plot#pandas.DataFrame.plot\n",
    "* pd.loc[]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html?highlight=loc#pandas.DataFrame.loc\n",
    "* plot latitude and longitude: https://jakevdp.github.io/PythonDataScienceHandbook/04.13-geographic-data-with-basemap.html  & https://stackoverflow.com/questions/53233228/plot-latitude-longitude-from-csv-in-python-3-6\n",
    "* to_numpy():https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html?highlight=to_numpy#pandas.DataFrame.to_numpy &  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.to_numpy.html?highlight=to_numpy#pandas.Index.to_numpy\n",
    "* loc:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html?highlight=loc#pandas.DataFrame.loc\n",
    "* Getting distance between two points based on latitude/longitude: https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "* Geographiclib: https://geographiclib.sourceforge.io/html/python/code.html#module-geographiclib.geodesic\n",
    "* array: https://numpy.org/doc/stable/reference/generated/numpy.array.html?highlight=array#numpy.array\n",
    "* matrix: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html?highlight=matrix#numpy.matrix\n",
    "* linalg.solve():https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html#numpy.linalg.solve\n",
    "* isna() :https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html\n",
    "* dropna(): drop missing data https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "* linearRegression:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* fit(): Fit linear model.https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* reshape():Gives a new shape to an array without changing its data.https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\n",
    "* boxplot: https://seaborn.pydata.org/generated/seaborn.boxplot.html & https://jwalton.info/Matplotlib-custom-boxplots/\n",
    "* percentile: https://numpy.org/doc/stable/reference/generated/numpy.percentile.html?highlight=percentile#numpy.percentile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
