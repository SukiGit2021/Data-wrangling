{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT 5196 Assignment 3\n",
    "* Name: Peiyu Liu\n",
    "* Student Number: 31153291\n",
    "* Data: 09/06/2021\n",
    "\n",
    "### Libraries used:\n",
    "* pandas: handle data, load files, convert files and filter data.use pandas to read data files.\n",
    "* numpy: handle array and narray data, process matrix oeprations.\n",
    "* json: load json file. like School.json file.\n",
    "* BeautifulSoup: pulling data out of HTML and XML files.\n",
    "* shapefile: provides read and write support for the Shapefile format\n",
    "* Point: drawing function on an image, take x,y arguments.\n",
    "* shape: drawing shape on an image for data.\n",
    "* math: contain mathematical functions for data calculation.\n",
    "* os: load and handle files.\n",
    "* datatime: manupulate dates and times to calculate stations schedule time.\n",
    "* preprocessing: transfer classes to raw feature vector into downstream estimators.\n",
    "* LinearRegression: use this function to observe target dataset and predict linear.\n",
    "* pyplot: interactive drawing and procedural drawing.\n",
    "* scipy: includes modules for optimization, linear algebra, integration, interpolation, and special functions\n",
    "* seaborn: data visualization library based on matplotlib to generate visualization digram.\n",
    "* matplotlib: graphical data and provide diversified output formats.\n",
    "* warnings: ignore warning notification.\n",
    "\n",
    "\n",
    "### Reference:\n",
    "* Point: https://www.geeksforgeeks.org/wand-point-function-in-python/ , https://shapely.readthedocs.io/en/stable/manual.html , https://pypi.org/project/Shapely/ , https://automating-gis-processes.github.io/site/notebooks/L1/geometric-objects.html\n",
    "* BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "* shapefile: https://pypi.org/project/pyshp/#overview , https://gis.stackexchange.com/questions/113799/how-to-read-a-shapefile-in-python\n",
    "* shape: https://pypi.org/project/Shapely/\n",
    "* math: https://docs.python.org/3/library/math.html\n",
    "* datatime: https://docs.python.org/3/library/datetime.html\n",
    "* preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "* LinearRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* pyplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "* scipy: https://docs.scipy.org/doc/scipy/reference/tutorial/special.html\n",
    "* seaborn: https://seaborn.pydata.org/introduction.html\n",
    "* warnings: https://docs.python.org/3/library/warnings.html\n",
    "* matplotlib: https://matplotlib.org/stable/tutorials/introductory/pyplot.html\n",
    "\n",
    "\n",
    "# 1. Introduction\n",
    "* For assignment 3, I need to handle some data files in different file types. The real estate data file is a CSV file, and it contains many data information like property id, latitude, longitude and so on.  so I use the pandas' function to read the real estate file. Real estate data also have an XML file, so I open the XML file and use the beautifulsoup function to reformat the file and use the dictionary to store keys and values. After process data in these two files, I use the pandas function to combine two files and drop duplications. Other files like a hospital in xlsx type, recreation file in HTML type, school file in JSON type, boundary files in dbf, prj, shp, shx type. There are also transition files, and files have information about stops, stop times, trips and calendars. after process these files, all data in these files should convert to dataframe, it is a better method to handle data in these files. I concat each file in one new file and generate a linear model to predict the “price” using “Distance_to_school”, “travel_min_to_CBD”, and “Distance_to_Recreation _centre” attributes.\n",
    "\n",
    "* important requirement: property id should be unique, travel time should be mean time (all times/ degree), trip should in 7-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and libraries to process data, details will explain in each section.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import shapefile\n",
    "from shapely.geometry import Point \n",
    "from shapely.geometry import shape\n",
    "from math import radians, cos, sin, asin, sqrt, acos\n",
    "from os import listdir\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "# ignore warning notificaiton when draw diagrams.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data file and observe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data file and observe variables information\n",
    "# read csv file using pandas function\n",
    "rsd_csv_file = pd.read_csv('31153291/real_estate_data.csv')\n",
    "rsd_csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete index\n",
    "# because I need to concat each file, each file has own index, so better to delete index of each file.\n",
    "rsd_csv_file = rsd_csv_file.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data file\n",
    "# open xml file and read data\n",
    "rsd_xml_file = open('31153291/real_estate_data.xml')\n",
    "rsd__xml_data = rsd_xml_file.read()\n",
    "\n",
    "# read data and change data group format\n",
    "# pulling relestate data to lxml format.\n",
    "# Reference: BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "rsd_soup = BeautifulSoup(rsd__xml_data,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* generate dictionary to store variables' keys and values\n",
    "* store data like this format: easy to find key to value.\n",
    "{'property_id': [],\n",
    " 'lat': [],\n",
    " 'lng': [],\n",
    " 'addr_street': [],\n",
    " 'price': [],\n",
    " 'property_type': [],\n",
    " 'year': [],\n",
    " 'bedrooms': [],\n",
    " 'bathrooms': [],\n",
    " 'parking_space': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsd_columns = [[] for flag in range(len(rsd_csv_file.columns))]\n",
    "rsd_dict = dict(zip(rsd_csv_file.columns, rsd_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all type child nodes of the current type to determine whether the filter conditions are met\n",
    "# Reference: (beautifulsoup find_all(): https://blog.csdn.net/depers15/article/details/51934210)\n",
    "for flag in rsd_dict.keys():\n",
    "    type_list = rsd_soup.find(flag).find_all(type)\n",
    "    \n",
    "# Get all types and concatenate them using the given delimiter.\n",
    "# Referece: (get_text(): https://blog.csdn.net/f156207495/article/details/78074240)\n",
    "    for flag_ in type_list:\n",
    "        rsd_dict[flag].append(flag_.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer dictionary to dataframe format\n",
    "# all files need to be dataframe format. easy to handle\n",
    "rsd_df = pd.DataFrame(rsd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lambda to traversal relestate dataframe to reshape dataframe by filter add and property type.\n",
    "# Reference: lambda:https://www.guru99.com/python-lambda-function.html\n",
    "for flag in rsd_df.columns:\n",
    "    if flag != 'addr_street' and flag != 'property_type':\n",
    "        # flag should be: property_id,lat,lng,price,year,bedrooms,bathrooms,parking_space\n",
    "        rsd_df[flag] = rsd_df[flag].apply(lambda flag: float(flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine realestate xml file and html file, delete index. after combine two files then delete copy data.\n",
    "# Reference: concat: https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html\n",
    "# drop_duplications: https://blog.csdn.net/csefrfvdv/article/details/100770965\n",
    "combine_rsd = pd.concat([rsd_df, rsd_csv_file], ignore_index = True)\n",
    "combine_rsd = combine_rsd.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add lists  to new realestate dataframe. lists sizes are equal to index length. uniform each variables numbers.\n",
    "* Create a list and add a header to the list and the number of rows in each header must be the same.\n",
    "* Reference: https://www.codenong.com/10712002/, https://stackoverflow.com/questions/10712002/create-an-empty-list-in-python-with-certain-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lists  to new realestate dataframe. lists sizes are equal to index length. uniform each variables numbers.\n",
    "# Create a list and add a header to the list and the number of rows in each header must be the same.\n",
    "# Reference: https://www.codenong.com/10712002/, https://stackoverflow.com/questions/10712002/create-an-empty-list-in-python-with-certain-size\n",
    "new_rsd_size = len(combine_rsd.index) \n",
    "combine_rsd['suburb'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['School_id'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Distance_to_school'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Train_station_id'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Distance_to_train_station'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['travel_min_to_CBD'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Transfer_flag'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Hospital_id'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Distance_to_hospital'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Recreation_centre_id'] = ['no meaning'] * new_rsd_size\n",
    "combine_rsd['Distance_to_Recreation_centre'] = ['no meaning'] * new_rsd_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add all variables to list: 'property_id', 'lat', 'lng', 'addr_street', 'suburb', 'price', 'property_type', 'year', 'bedrooms', 'bathrooms','parking_space', 'School_id', 'Distance_to_school', 'Train_station_id', 'Distance_to_train_station','travel_min_to_CBD', 'Transfer_flag', 'Hospital_id', 'Distance_to_hospital', 'Recreation_centre_id','Distance_to_Recreation_centre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd = combine_rsd[\n",
    "    ['property_id', 'lat', 'lng', 'addr_street', 'suburb', 'price', 'property_type', 'year', 'bedrooms', 'bathrooms',\n",
    "     'parking_space', 'School_id', 'Distance_to_school', 'Train_station_id', 'Distance_to_train_station',\n",
    "     'travel_min_to_CBD', 'Transfer_flag', 'Hospital_id', 'Distance_to_hospital', 'Recreation_centre_id',\n",
    "     'Distance_to_Recreation_centre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### suburb\n",
    "* use shapefile reader function to read shapefile file and recrod attribute from file.\n",
    "* read supplementary_data/vic_suburb_boundary/VIC_LOCALITY_POLYGON_shp.shp \n",
    "* Reference: read shapefile: https://blog.csdn.net/sgcc_zhs/article/details/75142599\n",
    "* compare matching latitude and longitude to find correct suburb and add suburb to file.\n",
    "* using a function called .within() that checks if a point is within.\n",
    "* Reference: check within point in suburb boundary: https://automating-gis-processes.github.io/CSC18/lessons/L4/point-in-polygon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0, ['lat', 'lng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shapefile reader function to read shapefile file and recrod attribute from file.\n",
    "suburb_file = shapefile.Reader('supplementary_data/vic_suburb_boundary/VIC_LOCALITY_POLYGON_shp.shp')\n",
    "suburb_shape = suburb_file.shapes()\n",
    "suburb_records = suburb_file.records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set required parameters\n",
    "def sub_find(lat, lng, suburb_shape=suburb_shape, suburb_records=suburb_records):\n",
    "    for flag in range(len(suburb_shape)):\n",
    "        sub_bound = suburb_shape[flag]\n",
    "        # use Point within() function to check point in suburb limitation.\n",
    "        if Point((lng, lat)).within(shape(sub_bound)):\n",
    "            return suburb_records[flag][-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traversal all each index and row in rsd container file to compare suburb latitude and longitude.\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    match_suburb = sub_find(flag_row.lat, flag_row.lng)\n",
    "    # once find matching geographical data, add correct suburb to rsd file.\n",
    "    combine_rsd.loc[flag_index, 'suburb'] = match_suburb\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### school data\n",
    "* read school file,json file can read directly.\n",
    "* group school latitude and longitude data.\n",
    "* generate dictionary and zip school information to new format.\n",
    "* transfer school data to dict format: school id: school geographic data -- {12: array([-37.74, 145.21])}\n",
    "* use math function to calculate radians distance.\n",
    "* Calculate the distance between two latitude and longitude\n",
    "* Longitude and latitude converted to radians\n",
    "* Use the average radius of the earth\n",
    "* return result in Three decimal places\n",
    "* Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points ， https://www.w3resource.com/python-exercises/python-basic-exercise-40.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file and show header.\n",
    "school_file = pd.read_json('31153291/School.json')\n",
    "school_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dictionary and zip school information to new format.\n",
    "# transfer school data to dict format: school id: school geographic data -- {12: array([-37.74, 145.21])}\n",
    "school_dic = dict(zip(school_file.School_ID.to_list(), school_file[['Lat', 'Long']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between two latitude and longitude\n",
    "# Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points , https://www.w3resource.com/python-exercises/python-basic-exercise-40.php\n",
    "def calculator(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    # Longitude and latitude converted to radians\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # Use the average radius of the earth\n",
    "    r = 6378\n",
    "    # return result in Three decimal places\n",
    "    return round(c * r, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_names = list(school_dic.keys())\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    cal_container = []\n",
    "    for key in school_dic.keys():\n",
    "        # key: 0 index is latitude, 1 index is longitude\n",
    "        cal_dice = calculator(flag_row.lat, flag_row.lng, school_dic[key][0], school_dic[key][1])\n",
    "        cal_container.append(cal_dice)\n",
    "        # calculate minimum\n",
    "    min_dist = min(cal_container)\n",
    "    school_indx = cal_container.index(min_dist)\n",
    "    combine_rsd.loc[flag_index, 'School_id'] = school_names[school_indx]\n",
    "    # add minimum distance to matching school(using school id to pair)\n",
    "    combine_rsd.loc[flag_index, 'Distance_to_school'] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0, ['School_id', 'Distance_to_school']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hospital\n",
    "* read hospital file: xlsx file should transfer to dataframe then easy to process.\n",
    "* read xlsx file pages, read pages' name, only one page: Sheet1\n",
    "* Parameter analysis：parse hospital data.\n",
    "* reference： Parameter analysis： https://stackoverflow.com/questions/7372716/parsing-excel-documents-with-python , https://yangfangs.github.io/2016/12/13/python-argpaarse-usage/ \n",
    "* generate dictionary and zip hospital data into group: {id: latigude, longitude}.\n",
    "* use math function to calculate radians distance.\n",
    "* Calculate the distance between two latitude and longitude\n",
    "* Longitude and latitude converted to radians\n",
    "* Use the average radius of the earth\n",
    "* return result in Three decimal places\n",
    "* Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points ， https://www.w3resource.com/python-exercises/python-basic-exercise-40.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read xlsx file and read page's name\n",
    "hospital_xlsx_read = pd.ExcelFile('31153291/hospital.xlsx')\n",
    "hospital_xlsx_read.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter analysis： https://stackoverflow.com/questions/7372716/parsing-excel-documents-with-python\n",
    "hospital_data = hospital_xlsx_read.parse('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dictionary and zip hospital data into group: {id: [latigude, longitude]}.\n",
    "hospital_dic = dict(zip(hospital_data.id.to_list(), hospital_data[['lat', 'lng']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same manipuation like school.\n",
    "# Calculate the distance between two latitude and longitude\n",
    "# Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points\n",
    "hospital_names = list(hospital_dic.keys())\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    cal_container = []\n",
    "    for key in hospital_dic.keys():\n",
    "        # key: 0 index is latitude, 1 index is longitude\n",
    "        cal_dice = calculator(flag_row.lat, flag_row.lng, hospital_dic[key][0], hospital_dic[key][1])\n",
    "        cal_container.append(cal_dice)\n",
    "        # calculate minumum distance as hospital distance.\n",
    "    min_dist = min(cal_container)\n",
    "    index_hosp = cal_container.index(min_dist)\n",
    "    combine_rsd.loc[flag_index, 'Hospital_id'] = hospital_names[index_hosp]\n",
    "      # add minimum distance to matching hospital(using hospital id to pair)\n",
    "    combine_rsd.loc[flag_index, 'Distance_to_hospital'] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreation centre id\n",
    "* open and read html file\n",
    "* read data and change data group format\n",
    "* pulling relestate data to lxml format.\n",
    "* Reference: BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "* each part format: index 2 is latitude, index 3 is longitude.\n",
    "* use math function to calculate radians distance.\n",
    "* Calculate the distance between two latitude and longitude\n",
    "* Longitude and latitude converted to radians\n",
    "* Use the average radius of the earth\n",
    "* return result in Three decimal places\n",
    "* Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points ， https://www.w3resource.com/python-exercises/python-basic-exercise-40.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreation_centre_id\n",
    "rc_html_read = open('31153291/Recreation_centres.html')\n",
    "rc_data = rc_html_read.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and change data group format\n",
    "# pulling relestate data to lxml format.\n",
    "# Reference: BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "rc_format = BeautifulSoup(rc_data, 'lxml')\n",
    "rc_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data format is <tr><td>MITCHE3674</td><td>Vermont South Club</td><td>-37.851683</td><td>145.180228</td></tr>\n",
    "rc_format.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 2 is latitude, index 3 is longitude\n",
    "rc_format.find_all('td')[2].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_info = rc_format.find_all('td')\n",
    "rc_container = {}\n",
    "# data format is <tr><td>MITCHE3674</td><td>Vermont South Club</td><td>-37.851683</td><td>145.180228</td></tr>\n",
    "for flag in range(0, len(rc_info), 4):\n",
    "    rc_id = rc_info[flag].get_text()\n",
    "    # index 2 is latitude, index 3 is longitude\n",
    "    rc_lat = rc_info[flag + 2].get_text()\n",
    "    rc_lng = rc_info[flag + 3].get_text()\n",
    "    # get latutide and longitude, then transfer them to float format.\n",
    "    # store float lantitude and longitude in containder.\n",
    "    rc_container[rc_id] = (float(rc_lat), float(rc_lng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function like school and hospital\n",
    "# Calculate the distance between two latitude and longitude\n",
    "# Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points\n",
    "recreat_names = list(rc_container.keys())\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    cal_container = []\n",
    "    for key in rc_container.keys():\n",
    "        #  key: 0 index is latitude, 1 index is longitude\n",
    "        cal_dice = calculator(flag_row.lat, flag_row.lng, rc_container[key][0], rc_container[key][1])\n",
    "        cal_container.append(cal_dice)\n",
    "        # calculate minumum distance as hospital distance.\n",
    "    min_dist = min(cal_container)\n",
    "    index_rc = cal_container.index(min_dist)\n",
    "    combine_rsd.loc[flag_index,'Recreation_centre_id'] = recreat_names[index_rc]\n",
    "     # add minimum distance to matching hospital(using hospital id to pair)\n",
    "    combine_rsd.loc[flag_index,'Distance_to_Recreation_centre'] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "* use os function to read each folder in gtfs document.\n",
    "#### notice: because my laptop is Mac, so there is empty file: DS_store in my gtfs file, so I use for loop to ignore this empty file.\n",
    "* read folder file in gtfs, each folder has stops.txt.\n",
    "* read stops.txt\n",
    "* traversal each stop stations' name.\n",
    "* find train stop stations.\n",
    "* transfer stop station data to dict format: stop name: stop geographic data -- {name: array([latitude, longitude])}\n",
    "* generate dictionary and zip stop information to new format.\n",
    "* transfer stop data to dict format: stop name: stop geographic data -- {name: array([-37.74, 145.21])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show folders in gtfs folder.\n",
    "for data_file in listdir('supplementary_data/gtfs/'):\n",
    "    print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use os function to read each folder in gtfs document.\n",
    "def file_group(filename, path='supplementary_data/gtfs/'):\n",
    "    file_flag = None\n",
    "    for file_name in listdir(path):\n",
    "# because my laptop is Mac, so there is empty file: DS_store in my gtfs file, so I use for loop to ignore this empty file.\n",
    "        if file_name == '.DS_Store': \n",
    "        # if file name is .DS_Store, ignore this file.\n",
    "            continue\n",
    "        file_path = pd.read_csv(path + '/' + file_name + '/google_transit/' + filename, sep=',')\n",
    "        if file_flag:\n",
    "            files_temp = pd.concat([files_temp, file_path], ignore_index=True)\n",
    "            print(files_temp)\n",
    "        else:\n",
    "            files_temp = file_path\n",
    "            file_flag = 1\n",
    "            # drop duplicated file.\n",
    "        files_temp = files_temp.drop_duplicates()\n",
    "        # reset file index.\n",
    "        files_temp = files_temp.reset_index(drop=True)\n",
    "    return files_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather stop stations data.\n",
    "gtfs_stop_file = file_group('stops.txt')\n",
    "gtfs_stop_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traversal and find stop name is Southern Cross.\n",
    "gtfs_stop_file[gtfs_stop_file.stop_name.apply(lambda flag: 'Southern Cross' in flag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter Railway Station/ because I only need train stop stations.\n",
    "gtfs_stop_file = gtfs_stop_file[gtfs_stop_file.stop_name.apply(lambda flag: 'Railway Station' in flag and 'Railway Station/' not in flag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stop stations' name is unique.\n",
    "gtfs_stop_file.stop_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dictionary and zip stop information to new format.\n",
    "# transfer school data to dict format: school id: school geographic data -- {12: array([-37.74, 145.21])}\n",
    "stop_container = dict(zip(gtfs_stop_file.stop_id.to_list(),gtfs_stop_file[['stop_lat','stop_lon']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function like school and hospital\n",
    "# Calculate the distance between two latitude and longitude\n",
    "# Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points\n",
    "stop_names = list(stop_container.keys())\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    cal_container = []\n",
    "    for key in stop_container.keys():\n",
    "         #  key: 0 index is latitude, 1 index is longitude\n",
    "        cal_dice = calculator(flag_row.lat, flag_row.lng, stop_container[key][0], stop_container[key][1])\n",
    "        cal_container.append(cal_dice)\n",
    "        # calculate minumum distance as hospital distance.\n",
    "    min_dist = min(cal_container)\n",
    "    stop_indx = cal_container.index(min_dist)\n",
    "    combine_rsd.loc[flag_index, 'Train_station_id'] = stop_names[stop_indx]\n",
    "     # add minimum distance to matching train station(using station id to pair)\n",
    "    combine_rsd.loc[flag_index, 'Distance_to_train_station'] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# travel_min_to_CBD\n",
    "route_data = file_group('routes.txt')\n",
    "schedule_stop = file_group('stop_times.txt')\n",
    "calendar_data = file_group('calendar.txt')\n",
    "trip_data = file_group('trips.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need schedule >= 7am and <= 9am\n",
    "# use 2pm can get all 9am.\n",
    "schedule_stop = schedule_stop[(schedule_stop.departure_time >= '07:00:00') & (schedule_stop.departure_time <= '14:00:00')]\n",
    "schedule_stop = schedule_stop.reset_index(drop=True)\n",
    "schedule_stop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get array:array(['T0', 'T0_1', 'T0_2', 'T0_3', 'T0_4', 'T0_5', 'T0_6', 'T0_7',\n",
    "       'T0_8', 'T0_9', 'T0', 'T0_1', 'T0_2', 'T0_1', 'T0_10', 'T0_11',\n",
    "       'T0_12', 'T0_13', 'T0_14', 'T0_15', 'T0_16', 'T0_17', 'T0_18',\n",
    "       'T0_19', 'T0_20', 'T0_21', 'T0_22', 'T0_23', 'T0_3', 'T0_4',\n",
    "       'T0_5', 'T0_6', 'T0_7', 'T0_8', 'T0_9', 'T0'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_service = calendar_data[(calendar_data.monday == 1) & (calendar_data.tuesday == 1) & (calendar_data.wednesday == 1) & (\n",
    "            calendar_data.thursday == 1) & (calendar_data.friday == 1)].service_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: isin() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html\n",
    "# check the element is included in the value\n",
    "trip_container = trip_data[trip_data.service_id.isin(calendar_service)].trip_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trip_container), len(set(trip_container)) # check length is same to ensure data is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find southern cross station\n",
    "gtfs_stop_file.head()\n",
    "for flag in gtfs_stop_file.stop_name:\n",
    "    if 'Southern Cross' in flag:\n",
    "        print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stop stations' id\n",
    "gtfs_stop_file[gtfs_stop_file.stop_name == 'Southern Cross Railway Station (Melbourne City)'].stop_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_stop_file[gtfs_stop_file.stop_id == 20043]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrsmc = gtfs_stop_file[gtfs_stop_file.stop_name == 'Southern Cross Railway Station (Melbourne City)'].stop_id.values\n",
    "scrsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop[schedule_stop.stop_id == 20043].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop[schedule_stop.trip_id == '1022.UJ.1-V48-H-mjp-1.6.R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop[schedule_stop.stop_id == 22180].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop[schedule_stop.trip_id == '1.T5.2-WMN-C-mjp-1.1.H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_filter = []\n",
    "# check the element is included in the value\n",
    "matched_trips = schedule_stop[schedule_stop.stop_id.isin(scrsmc)].trip_id.unique()\n",
    "for flag in matched_trips:\n",
    "    if flag in trip_container:\n",
    "        trip_filter.append(flag)\n",
    "schedule_stop = schedule_stop[schedule_stop.trip_id.isin(trip_filter)]\n",
    "trip_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_container = schedule_stop[schedule_stop.trip_id.isin(trip_filter)].stop_id.unique()\n",
    "stations_df = gtfs_stop_file[gtfs_stop_file.stop_id.isin(stations_container)]\n",
    "\n",
    "# generate dictionary and zip stop information to new format.\n",
    "# transfer school data to dict format: stop id: stop geographic data -- {id: array([-37.74, 145.21])}\n",
    "stations_dict = dict(zip(stations_df.stop_id.tolist(),stations_df[['stop_lat','stop_lon']].values))\n",
    "stations_dict # all related station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use departure time and arrival time to calculate spend time\n",
    "def calculate_time(dep_time, arr_time):\n",
    "    # set time format.\n",
    "    time_format = '%H:%M:%S'\n",
    "    time_diff = datetime.strptime(arr_time, time_format) - datetime.strptime(dep_time, time_format)\n",
    "    # transfer spend time to minutes\n",
    "    time_min_format = round(time_diff.seconds / 60)\n",
    "    return time_min_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.Train_station_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_stop[schedule_stop.stop_id == 20022].trip_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsid_unique = combine_rsd.Train_station_id.unique()\n",
    "\n",
    "# stop should in 7am-9am\n",
    "# stop station should be id 20043,22180\n",
    "def cal_stop(tsid_unique, trip_filter=trip_filter, schedule_stop=schedule_stop):\n",
    "    st_container = {}\n",
    "    for id_flag in tsid_unique:\n",
    "        st_container[id_flag] = []\n",
    "        matched_trips = schedule_stop[schedule_stop.stop_id == id_flag].trip_id.values\n",
    "        for trips in matched_trips:\n",
    "            dep_time = schedule_stop[(schedule_stop.trip_id == trips) & (schedule_stop.stop_id == id_flag)].departure_time.values[0]\n",
    "            try:\n",
    "                arr_time = schedule_stop[(schedule_stop.trip_id == trips) & (schedule_stop.stop_id == 20043)].arrival_time.values[0]\n",
    "            except:\n",
    "                 arr_time = schedule_stop[(schedule_stop.trip_id == trips) & (schedule_stop.stop_id == 22180)].arrival_time.values[0]\n",
    "            if dep_time <= arr_time and dep_time <= '09:00:00':\n",
    "                spend_time = calculate_time(dep_time, arr_time)\n",
    "                st_container[id_flag].append(spend_time)\n",
    "        if st_container[id_flag]:\n",
    "            st_container[id_flag] = np.mean(st_container[id_flag])\n",
    "        else:\n",
    "            st_container[id_flag] = 0\n",
    "    return st_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the element is included in the value\n",
    "combine_rsd[combine_rsd.Train_station_id.isin(scrsmc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_container = cal_stop(stations_container, trip_filter=trip_filter)\n",
    "st_container # including all stations in schedule_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop_times = {}\n",
    "for key in st_container.keys():\n",
    "    if st_container[key]:\n",
    "        new_stop_times[key] = st_container[key]\n",
    "st_container = new_stop_times\n",
    "st_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag and cbd\n",
    "for flag_index, flag_row in combine_rsd.iterrows():\n",
    "    if flag_row.Train_station_id in st_container.keys():\n",
    "        combine_rsd.loc[flag_index, 'Transfer_flag'] = 0\n",
    "        combine_rsd.loc[flag_index, 'travel_min_to_CBD'] = st_container[flag_row.Train_station_id]\n",
    "    else:\n",
    "        combine_rsd.loc[flag_index, 'Transfer_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function like school and hospital\n",
    "# Calculate the distance between two latitude and longitude\n",
    "# Reference: math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points\n",
    "flag1_transfer = combine_rsd[combine_rsd.Transfer_flag == 1]\n",
    "for flag_index,flag_row in flag1_transfer.iterrows():\n",
    "    cal_container = []\n",
    "    for key in st_container.keys():\n",
    "        # key index 0 is latitude, 1 is longitude\n",
    "        cal_dice = calculator(flag_row.lat,flag_row.lng, stop_container[key][0],stop_container[key][1])\n",
    "        cal_container.append((cal_dice,key))\n",
    "        # calculate minimum distance\n",
    "    min_dist = min(cal_container)\n",
    "    station_new = min_dist[1]\n",
    "         # add minimum distance to matching travel(using to pair)\n",
    "    combine_rsd.loc[flag_index,'travel_min_to_CBD'] = st_container[station_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd[combine_rsd.Transfer_flag == 1].travel_min_to_CBD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rsd.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change each variables to dataframe foramt and easy to combine each variables into one df file.\n",
    "combine_rsd.School_id = combine_rsd.School_id.apply(lambda flag: float(flag))\n",
    "combine_rsd.Distance_to_school = combine_rsd.Distance_to_school.apply(lambda flag: float(flag))\n",
    "combine_rsd.Distance_to_train_station = combine_rsd.Distance_to_train_station.apply(lambda flag: float(flag))\n",
    "combine_rsd.travel_min_to_CBD = combine_rsd.travel_min_to_CBD.apply(lambda flag: float(flag))\n",
    "combine_rsd.Transfer_flag = combine_rsd.Transfer_flag.apply(lambda flag: float(flag))\n",
    "combine_rsd.Hospital_id = combine_rsd.Hospital_id.apply(lambda flag: flag)\n",
    "combine_rsd.Distance_to_hospital = combine_rsd.Distance_to_hospital.apply(lambda flag: float(flag))\n",
    "combine_rsd.Recreation_centre_id = combine_rsd.Recreation_centre_id.apply(lambda flag: flag)\n",
    "combine_rsd.Distance_to_Recreation_centre = combine_rsd.Distance_to_Recreation_centre.apply(lambda flag: float(flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify property id name\n",
    "combine_rsd = combine_rsd.rename(columns = {'property_id':'Property_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output result\n",
    "combine_rsd.to_csv('31153291_A3_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reshaping\n",
    "* The influence of different normalization/conversion methods (ie normalization, min-max normalization, logarithm, power, box-cox conversion) on the properties of \"price\", \"Distance_to_school\", \"travel_min_to_CBD\" and \"Distance_to_Recreation_centre\".\n",
    "* data preprocessing methods: StandardScaler function\n",
    "* Adjust the distribution of the feature data to the standard normal distribution, also called the Gaussian distribution, which means that the mean dimension of the data is 0 and the variance is 1. After the standard conversion operation is performed on the training data set, the same conversion is applied to the test training set, Use fit function to match this training set.\n",
    "* reference: https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/ , https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "* Load data set\n",
    "* Import model parameters\n",
    "* Training model\n",
    "* sklearn.linear_model.LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=1), fit trains on the training set X, y. score returns the predicted coefficient of determination R^2.\n",
    "* Reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html , https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "##### notice: diagram methods' code are reference to lecture and tutorial code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the distribution of the feature data to the standard normal distribution, also called the Gaussian distribution, \n",
    "# which means that the mean dimension of the data is 0 and the variance is 1. \n",
    "# After the standard conversion operation is performed on the training data set, \n",
    "# the same conversion is applied to the test training set, Use fit function to match this training set.\n",
    "standard_model = preprocessing.StandardScaler().fit(combine_rsd[['price', 'Distance_to_school',\n",
    "                                                   'travel_min_to_CBD',\n",
    "                                                   'Distance_to_Recreation_centre']])\n",
    "model_format = standard_model.transform(combine_rsd[['price', 'Distance_to_school',\n",
    "                                 'travel_min_to_CBD',\n",
    "                                 'Distance_to_Recreation_centre']])\n",
    "\n",
    "model_format[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy list to forbid modifying raw list.\n",
    "duplication_df = combine_rsd[['price', 'Distance_to_school',\n",
    "             'travel_min_to_CBD',\n",
    "             'Distance_to_Recreation_centre']].copy()\n",
    "# four variables: price, distance_to_school, travel_min_to_CBD,distance_to_rc.\n",
    "# index is 0,1,2,3\n",
    "duplication_df['priced'] = model_format[:, 0]\n",
    "duplication_df['Distance_to_schooled'] = model_format[:, 1]\n",
    "duplication_df['travel_min_to_CBDed'] = model_format[:, 2]\n",
    "duplication_df['Distance_to_Recreation_centred'] = model_format[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplication_df['price'].plot(), duplication_df['priced'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_a = duplication_df[['Distance_to_schooled',\n",
    "            'travel_min_to_CBDed',\n",
    "            'Distance_to_Recreation_centred']]\n",
    "parameter_b = duplication_df['priced']\n",
    "#  Load data set\n",
    "# Import model parameters\n",
    "# Training model\n",
    "# sklearn.linear_model.LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=1),\n",
    "# fit trains on the training set X, y. \n",
    "# score returns the predicted coefficient of determination R^2.\n",
    "# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html , https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "linear_regression = LinearRegression().fit(parameter_a,parameter_b)\n",
    "linear_regression.score(parameter_a,parameter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplication_df = combine_rsd[['price', 'Distance_to_school',\n",
    "                                                   'travel_min_to_CBD',\n",
    "                                                   'Distance_to_Recreation_centre']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit trains on the training set. \n",
    "limit_value = preprocessing.MinMaxScaler().fit(duplication_df)\n",
    "limit_value_format = limit_value.transform(duplication_df)\n",
    "limit_value_format[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplication_df = combine_rsd[['price', 'Distance_to_school',\n",
    "             'travel_min_to_CBD',\n",
    "             'Distance_to_Recreation_centre']].copy()\n",
    "duplication_df['priced'] = limit_value_format[:, 0]\n",
    "duplication_df['Distance_to_schooled'] = limit_value_format[:, 1]\n",
    "duplication_df['travel_min_to_CBDed'] = limit_value_format[:, 2]\n",
    "duplication_df['Distance_to_Recreation_centred'] = limit_value_format[:, 3]\n",
    "\n",
    "# min - max[0-1]\n",
    "duplication_df[['priced', 'Distance_to_schooled',\n",
    "             'travel_min_to_CBDed',\n",
    "             'Distance_to_Recreation_centred']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter reference: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "# Drawing of scatter plot\n",
    "# Data mapping to the visual interface\n",
    "def plot():\n",
    "    f= plt.figure(figsize = (8,6))\n",
    "    plt.scatter(model_format[:,0], model_format[:,1], color='red', label='Standardized u=0, s=1 price', alpha=0.3)\n",
    "    plt.scatter(model_format[:,1], model_format[:,1], color='green', label='Standardized u=0, s=1 Dist_school', alpha=0.3)\n",
    "    plt.scatter(limit_value_format[:,0], limit_value_format[:,1], color='blue', label='min-max scaled [min=0, max=1] Dist_school', alpha=0.3)\n",
    "    plt.title('plot digram') \n",
    "    plt.xlabel('x')  # Set the label of the x-axis\n",
    "    plt.ylabel('y') # Set the label of the y-axis\n",
    "    plt.grid() \n",
    "    plt.tight_layout()\n",
    "# Whether there is a numerical or quantitative correlation trend between features, and whether the trend is linear or non-linear;\n",
    "# Observe whether there is noise in the data, and intuitively judge whether the noise will have a great impact on the model.\n",
    "# reference: https://blog.csdn.net/weixin_40683253/article/details/87367437\n",
    "plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_a = duplication_df[['Distance_to_schooled',\n",
    "            'travel_min_to_CBDed',\n",
    "            'Distance_to_Recreation_centred']]\n",
    "parameter_b = duplication_df['priced']\n",
    "linear_regression = LinearRegression().fit(parameter_a,parameter_b)\n",
    "linear_regression.score(parameter_a,parameter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log \n",
    "duplication_df = combine_rsd[['price', 'Distance_to_school', 'travel_min_to_CBD', 'Distance_to_Recreation_centre']].copy()\n",
    "duplication_df['priced'] = np.log2(combine_rsd.price) \n",
    "duplication_df['Distance_to_schooled'] = np.log2(combine_rsd.Distance_to_school) #\n",
    "duplication_df['travel_min_to_CBDed'] = np.log2(combine_rsd.travel_min_to_CBD) #\n",
    "duplication_df['Distance_to_Recreation_centred'] = np.log2(combine_rsd.Distance_to_Recreation_centre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplication_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(duplication_df.price, duplication_df.priced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_a = duplication_df[['Distance_to_schooled',\n",
    "            'travel_min_to_CBDed',\n",
    "            'Distance_to_Recreation_centred']]\n",
    "parameter_b = duplication_df['priced']\n",
    "linear_regression = LinearRegression().fit(parameter_a,parameter_b)\n",
    "linear_regression.score(parameter_a,parameter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#power\n",
    "duplication_df = combine_rsd[['price', 'Distance_to_school', 'travel_min_to_CBD', 'Distance_to_Recreation_centre']].copy()\n",
    "duplication_df['priced'] = combine_rsd['price']**2 \n",
    "duplication_df['Distance_to_schooled'] = combine_rsd.Distance_to_school**2 #\n",
    "duplication_df['travel_min_to_CBDed'] = combine_rsd.Distance_to_Recreation_centre**2 #\n",
    "duplication_df['Distance_to_Recreation_centred'] = combine_rsd.travel_min_to_CBD**2 #\n",
    "# min-max [0-1] \n",
    "duplication_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter reference: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "plt.scatter(duplication_df.price, duplication_df.priced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_a = duplication_df[['Distance_to_schooled',\n",
    "            'travel_min_to_CBDed',\n",
    "            'Distance_to_Recreation_centred']]\n",
    "parameter_b = duplication_df['priced']\n",
    "#  Load data set\n",
    "# Import model parameters\n",
    "# Training model\n",
    "# sklearn.linear_model.LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=1),\n",
    "# fit trains on the training set X, y. \n",
    "# score returns the predicted coefficient of determination R^2.\n",
    "# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html , https://scikit-learn.org/stable/modules/linear_model.html\n",
    "linear_regression = LinearRegression().fit(parameter_a,parameter_b)\n",
    "linear_regression.score(parameter_a,parameter_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxcox:\n",
    "# Reference: scipy.stats.boxcox: http://blog.17baishi.com/7230/ , \n",
    "# https://www.geeksforgeeks.org/box-cox-transformation-using-python/, https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html\n",
    "def plot_generation(raw_data):\n",
    "    original_data = raw_data\n",
    "    matched_data, matched_lambda = stats.boxcox(original_data)\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    #  # Use Box-Cox transformation to convert the data to normal, reducing the unobservable error and the correlation between the predictor variables. The main feature of Box-Cox transformation is to introduce a parameter, \n",
    "    sns.distplot(original_data, hist=False, kde=True, kde_kws={'shade': True, 'linewidth': 2},\n",
    "                 label=\"Non-Normal\", color=\"green\", ax=ax[0])\n",
    "    sns.distplot(matched_data, hist=False, kde=True, kde_kws={'shade': True, 'linewidth': 2},\n",
    "                 label=\"Normal\", color=\"green\", ax=ax[1])\n",
    "    plt.legend(loc = 'upper right')\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(10)\n",
    "    # # and estimate the parameter through the data itself to determine the data transformation form that should be adopted.\n",
    "    print(f\"Transformation: {matched_lambda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplication_df = combine_rsd[['price', 'Distance_to_school', 'travel_min_to_CBD', 'Distance_to_Recreation_centre']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag in duplication_df.columns:\n",
    "    plot_generation(duplication_df[flag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* It took me a lot of energy and time to complete assignment 3. I need to process separate files. The file formats are different. There are Excel, json, html, and shapefiles. I need to convert the data in each file The format is converted into a unified dataframe, and each file has associated corresponding data. Through these data, I can combine each file to form a large file. In the large file, the data in each file can be integrated, and each file can be processed. The data of each file corresponds to the data between the files through the corresponding latitude, longitude, id, and name, and fills them into the new file. By completing this process, my ability to analyze the data and match the data It has been greatly improved. In task2, I used multiple data analysis and drawing methods to visualize my data, allowing me to observe the distribution of my data more intuitively and conveniently. Through the training of assignment 3, I have mastered the visualization methods that are not proficient in teaching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference: \n",
    "* Point: https://www.geeksforgeeks.org/wand-point-function-in-python/ , https://shapely.readthedocs.io/en/stable/manual.html , https://pypi.org/project/Shapely/ , https://automating-gis-processes.github.io/site/notebooks/L1/geometric-objects.html\n",
    "* BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "* shapefile: https://pypi.org/project/pyshp/#overview , https://gis.stackexchange.com/questions/113799/how-to-read-a-shapefile-in-python\n",
    "* shape: https://pypi.org/project/Shapely/\n",
    "* math: https://docs.python.org/3/library/math.html\n",
    "* datatime: https://docs.python.org/3/library/datetime.html\n",
    "* preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "* LinearRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* pyplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "* scipy: https://docs.scipy.org/doc/scipy/reference/tutorial/special.html\n",
    "* seaborn: https://seaborn.pydata.org/introduction.html\n",
    "* warnings: https://docs.python.org/3/library/warnings.html\n",
    "* matplotlib: https://matplotlib.org/stable/tutorials/introductory/pyplot.html\n",
    "* list: https://www.codenong.com/10712002/, https://stackoverflow.com/questions/10712002/create-an-empty-list-in-python-with-certain-size\n",
    "* linearregression：https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html , https://scikit-learn.org/stable/modules/linear_model.html\n",
    "* standardscale: https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/ , https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "* scipy.stats.boxcox: http://blog.17baishi.com/7230/ , https://www.geeksforgeeks.org/box-cox-transformation-using-python/, https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html\n",
    "* math distance: https://www.codegrepper.com/code-examples/python/python+calculate+distance+between+two+points\n",
    "* Parameter analysis： https://stackoverflow.com/questions/7372716/parsing-excel-documents-with-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
